{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_list = ['configCC7-0', 'configCC7-1', 'configCC7-2', 'configCC7-3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "symptom_file = '../ProJect-Conv-Agent/XPs/cat_dqn/output/CC7/n_cc7_126_symptoms.json'\n",
    "condition_file = '../ProJect-Conv-Agent/XPs/cat_dqn/output/CC7/n_cc7_20_conditions.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(data):\n",
    "    \"\"\"Replaces commas and line breaks in the source string\n",
    "       with a single space.\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : str\n",
    "        data string to be cleaned\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        the resulting string\n",
    "    \"\"\"\n",
    "    result = data.replace(\"\\r\\n\", \" \")\n",
    "    result = result.replace(\"\\r\", \" \")\n",
    "    result = result.replace(\"\\n\", \" \")\n",
    "    result = result.replace(\",\", \" \")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_check_data(data_filepath, provided_data, key_name):\n",
    "    \"\"\"load the authorized data and check if the\n",
    "       provided data are compliant with those.\n",
    "    Parameters\n",
    "    ----------\n",
    "    symptom_filepath :  str\n",
    "        path to a json file containing the authorized symptom data.\n",
    "        the minimum structure of the data should be:\n",
    "        {\n",
    "            key_data1: {\n",
    "                key_name: data-name1,\n",
    "                ...\n",
    "            },\n",
    "            key_data2: {\n",
    "                key_name: data-name2,\n",
    "                ...\n",
    "            },\n",
    "            ...\n",
    "        }\n",
    "    provided_data : list\n",
    "        list of syptoms as provided by the data from Synthea patient\n",
    "        generation\n",
    "    key_name : str\n",
    "        the key used to access the information of the same meaning\n",
    "        as the one in `provided_data`\n",
    "    Returns\n",
    "    -------\n",
    "    index_2_key: list\n",
    "        a list containing all the keys of the authorized data\n",
    "    name_2_index: dict\n",
    "        a dict mapping the name associated to the authorized data to an index\n",
    "    data: dict\n",
    "        the authorized data\n",
    "    \"\"\"\n",
    "\n",
    "    with open(data_filepath) as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    index_2_key = sorted(list(data.keys()))\n",
    "    for k in index_2_key:\n",
    "        data[k][key_name] = clean(data[k][key_name])\n",
    "    name_2_index = {data[index_2_key[i]][key_name]: i for i in range(len(index_2_key))}\n",
    "\n",
    "    data_names = [data[k][key_name] for k in index_2_key]\n",
    "    is_present = [elem in data_names for elem in provided_data]\n",
    "\n",
    "    has_all_data = all(is_present)\n",
    "\n",
    "    if not has_all_data:\n",
    "        index = is_present.index(False)\n",
    "        raise ValueError(\n",
    "            \"The provided symptom samples are not compliant with \"\n",
    "            + \"authorized symptoms in the json file: {} : {}\".format(\n",
    "                data_filepath, provided_data[index]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return index_2_key, name_2_index, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(config_list, symptom_file, condition_file, config_base_dir='../ProJect-Conv-Agent/XPs/cat_dqn/output/CC7'):\n",
    "    symptom_infos = load_and_check_data(\n",
    "        symptom_file, [], key_name=\"name\"\n",
    "    )\n",
    "    pathology_infos = load_and_check_data(\n",
    "        condition_file, [], key_name=\"condition_name\"\n",
    "    )\n",
    "    result = {}\n",
    "    for config in config_list:\n",
    "        stats_file = f'{config_base_dir}/{config}/evaluation_stats.pkl'\n",
    "        result_file = f'{config_base_dir}/{config}/metric_results.json'\n",
    "        result[config] = {}\n",
    "        with open(stats_file, 'rb') as f:\n",
    "            result[config]['data'] = pkl.load(f)\n",
    "        with open(result_file) as f:\n",
    "            result[config]['result'] = json.load(f)\n",
    "    return result, symptom_infos, pathology_infos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_confusion_matrix(confusion_matrix, class_names, normalize=False, figsize = (10,7), fontsize=14, ax=None):\n",
    "    \"\"\"Prints a confusion matrix, as returned by sklearn.metrics.confusion_matrix, as a heatmap.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    confusion_matrix: numpy.ndarray\n",
    "        The numpy.ndarray object returned from a call to sklearn.metrics.confusion_matrix. \n",
    "        Similarly constructed ndarrays can also be used.\n",
    "    class_names: list\n",
    "        An ordered list of class names, in the order they index the given confusion matrix.\n",
    "    figsize: tuple\n",
    "        A 2-long tuple, the first value determining the horizontal size of the ouputted figure,\n",
    "        the second determining the vertical size. Defaults to (10,7).\n",
    "    fontsize: int\n",
    "        Font size for axes labels. Defaults to 14.\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.figure.Figure\n",
    "        The resulting confusion matrix figure\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        confusion_matrix = confusion_matrix.astype('float') / confusion_matrix.sum(axis=1)[:, np.newaxis]        \n",
    "    df_cm = pd.DataFrame(\n",
    "        confusion_matrix, index=class_names, columns=class_names, \n",
    "    )\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots(figsize=figsize)\n",
    "    #fig = plt.figure(figsize=figsize)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    try:\n",
    "        heatmap = sns.heatmap(df_cm, annot=True, fmt=fmt, ax=ax)\n",
    "    except ValueError:\n",
    "        raise ValueError(\"Confusion matrix values must be integers.\")\n",
    "    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=fontsize)\n",
    "    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=45, ha='right', fontsize=fontsize)\n",
    "    #plt.ylabel('True label')\n",
    "    #plt.xlabel('Predicted label')\n",
    "    heatmap.set_ylabel('True label')\n",
    "    heatmap.set_xlabel('Predicted label')\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data, all_symptoms_info, all_patho_info = load_data(config_list, symptom_file, condition_file)\n",
    "symptoms_reverse_map = {all_symptoms_info[0][i]: i for i in range(len(all_symptoms_info[0]))}\n",
    "pathos_reverse_map = {all_patho_info[0][i]: i for i in range(len(all_patho_info[0]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_info = {\n",
    "    'pathos': [all_patho_info[0], all_patho_info[1]],\n",
    "    'symptoms': [all_symptoms_info[0], all_symptoms_info[1]],\n",
    "}\n",
    "with open('./data_info.json', \"w\") as f:\n",
    "    json.dump(data_info, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_config = widgets.Dropdown(options=config_list, description='Configuration')\n",
    "dropdown_patho = widgets.Dropdown(options=['All'] + all_patho_info[0], description='Pathology')\n",
    "\n",
    "item_layout = widgets.Layout(margin='0 0 50px 0')\n",
    "\n",
    "output_config = widgets.Output()\n",
    "\n",
    "output_metric = widgets.Output()\n",
    "output_turn_stats = widgets.Output()\n",
    "output_reward_stats = widgets.Output()\n",
    "output_simulated_symp_stats = widgets.Output()\n",
    "output_relevant_symp_stats = widgets.Output()\n",
    "output_simulated_ratio_stats = widgets.Output()\n",
    "output_relevancy_ratio_stats = widgets.Output()\n",
    "\n",
    "output_cm = widgets.Output()\n",
    "output_first_symptom_dist = widgets.Output()\n",
    "output_inquire_dist = widgets.Output()\n",
    "\n",
    "input_widgets = widgets.HBox([dropdown_config, dropdown_patho], layout=item_layout)\n",
    "\n",
    "metric1_widgets = widgets.HBox(\n",
    "    [output_metric, output_turn_stats, output_reward_stats, output_simulated_symp_stats],\n",
    "    layout=item_layout\n",
    ")\n",
    "metric2_widgets = widgets.HBox(\n",
    "    #[output_relevant_symp_stats, output_simulated_ratio_stats, output_relevancy_ratio_stats],\n",
    "    [output_relevant_symp_stats, output_relevancy_ratio_stats],\n",
    "    layout=item_layout\n",
    ")\n",
    "metrics = widgets.VBox([metric1_widgets, metric2_widgets], layout=item_layout)\n",
    "plots = widgets.Tab([output_cm, output_first_symptom_dist, output_inquire_dist])\n",
    "plots.set_title(0, 'Confusion Matrix')\n",
    "plots.set_title(1, 'First Symptom Distribution')\n",
    "plots.set_title(2, 'Inquired Symptom Distribution')\n",
    "\n",
    "accordion = widgets.Accordion(children=[output_config, metrics, plots])\n",
    "accordion.set_title(0, 'Data')\n",
    "accordion.set_title(1, 'Metrics')\n",
    "accordion.set_title(2, 'Plots')\n",
    "\n",
    "\n",
    "dashboard = widgets.VBox([input_widgets, accordion])\n",
    "\n",
    "def generate_stats_keys(base):\n",
    "    return [base + a for a in ['_Avg', '_Std', '_Median', '_Min', '_Max']]\n",
    "\n",
    "def plot_distribution(selected_data, key, title, figsize=None, fontsize=14):\n",
    "    x = list(selected_data[key].keys())\n",
    "    v = sorted([int(a) for a in x])\n",
    "    x = [str(b) for b in v]\n",
    "    y = [selected_data[key][a] for a in x]\n",
    "    symp = [all_symptoms_info[0][int(i)] for i in x]\n",
    "    max_value = max(y)\n",
    "    n_plots = len(symp) // 20\n",
    "    if n_plots*20 != len(symp):\n",
    "        n_plots = n_plots + 1\n",
    "    n_graphs = n_plots // 2        \n",
    "    if n_graphs*2 != n_plots:\n",
    "        n_graphs = n_graphs + 1\n",
    "    \n",
    "    # [6.4, 4.8]\n",
    "    if n_graphs==n_plots==1:\n",
    "        fig, axes = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        if figsize is None:\n",
    "            figsize = [6.5 * 2, 5 * n_graphs]\n",
    "        fig, axes = plt.subplots(n_graphs, 2, figsize=figsize)\n",
    "    for i in range(n_graphs):            \n",
    "        for j in range(2):\n",
    "            beg = (2*i+j)*20\n",
    "            if beg < len(symp):\n",
    "                end = min((2*i+j+1) * 20, len(symp))\n",
    "                ax = axes if n_graphs==n_plots==1 else axes[i, j]\n",
    "                barplot = sns.barplot(\n",
    "                    x=symp[beg:end], y=y[beg:end], order=symp[beg:end], \n",
    "                    orient='v', \n",
    "                    ax=ax\n",
    "                )\n",
    "                barplot.xaxis.set_ticklabels(\n",
    "                    barplot.xaxis.get_ticklabels(), \n",
    "                    rotation=90, \n",
    "                    ha='center', fontsize=fontsize\n",
    "                )\n",
    "                barplot.set_ylim(top=max_value)\n",
    "                \n",
    "                #barplot = sns.barplot(\n",
    "                #    y=symp[beg:end], x=y[beg:end], order=symp[beg:end], \n",
    "                #    orient='h', estimator=lambda x:x[0], \n",
    "                #    ax=ax\n",
    "                #)\n",
    "                #barplot.yaxis.set_ticklabels(\n",
    "                #    barplot.yaxis.get_ticklabels(), \n",
    "                #    rotation=0, \n",
    "                #    ha='right', fontsize=fontsize\n",
    "                #)\n",
    "    if not (n_graphs==n_plots==1):\n",
    "        plt.tight_layout()\n",
    "    return fig\n",
    "       \n",
    "\n",
    "    \n",
    "metric_keys = ['accuracy', 'balanced_accuracy', 'precision', 'recall', 'f1']\n",
    "turn_keys = generate_stats_keys('turns')\n",
    "reward_keys = generate_stats_keys('rewards')\n",
    "turn_keys_out = generate_stats_keys('turn')\n",
    "reward_keys_out = generate_stats_keys('reward')\n",
    "relevant_symp_keys = generate_stats_keys('num_relevant_symptoms')\n",
    "simulated_symp_keys = generate_stats_keys('num_simulated_symptoms')\n",
    "relevant_ratio_keys = generate_stats_keys('relevancy_symptoms_ratio')\n",
    "simulated_ration_keys = generate_stats_keys('simulated_symptoms_ratio')\n",
    "\n",
    "def common_filtering(config, patho):\n",
    "    output_config.clear_output()\n",
    "    \n",
    "    output_metric.clear_output()\n",
    "    output_turn_stats.clear_output()\n",
    "    output_reward_stats.clear_output()\n",
    "    output_simulated_symp_stats.clear_output()\n",
    "    output_relevant_symp_stats.clear_output()\n",
    "    output_simulated_ratio_stats.clear_output()\n",
    "    output_relevancy_ratio_stats.clear_output()\n",
    "    \n",
    "    output_cm.clear_output()\n",
    "    output_first_symptom_dist.clear_output()\n",
    "    output_inquire_dist.clear_output()\n",
    "    \n",
    "    if patho == 'All':\n",
    "        selected_data = all_data[config]['result']['global']\n",
    "    else:\n",
    "        selected_data = all_data[config]['result']['per_patho'][str(pathos_reverse_map[patho])]\n",
    "        \n",
    "    with output_metric:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in metric_keys]}, \n",
    "                index=metric_keys\n",
    "            )\n",
    "        )\n",
    "    with output_turn_stats:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in turn_keys]}, \n",
    "                index=turn_keys_out\n",
    "            )\n",
    "        )\n",
    "    with output_reward_stats:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in reward_keys]}, \n",
    "                index=reward_keys_out\n",
    "            )\n",
    "        )\n",
    "    with output_relevant_symp_stats:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in relevant_symp_keys]}, \n",
    "                index=relevant_symp_keys\n",
    "            )\n",
    "        )\n",
    "    with output_simulated_symp_stats:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in simulated_symp_keys]}, \n",
    "                index=simulated_symp_keys\n",
    "            )\n",
    "        )\n",
    "    with output_relevancy_ratio_stats:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in relevant_ratio_keys]}, \n",
    "                index=relevant_ratio_keys\n",
    "            )\n",
    "        )\n",
    "    with output_simulated_ratio_stats:\n",
    "        display(\n",
    "            pd.DataFrame(\n",
    "                {'Value': [selected_data[a] for a in simulated_ration_keys]}, \n",
    "                index=simulated_ration_keys\n",
    "            )\n",
    "        )\n",
    "        \n",
    "    if patho == 'All':        \n",
    "        with output_cm:\n",
    "            fig = print_confusion_matrix(\n",
    "                np.array(selected_data['confusion_matrix']),\n",
    "                [\n",
    "                    all_patho_info[0][i] if i !=-1 else \"N/A\" \n",
    "                    for i in selected_data['confusion_matrix_support']\n",
    "                ],\n",
    "            )\n",
    "            plt.show()\n",
    "    with output_first_symptom_dist:\n",
    "        fig = plot_distribution(selected_data, 'first_symptoms_count', 'First symptom distribution')\n",
    "        plt.show()\n",
    "        \n",
    "    with output_inquire_dist:\n",
    "        fig = plot_distribution(selected_data, 'inquired_symptoms_count', 'Inquired symptom distribution')\n",
    "        plt.show()\n",
    "        \n",
    "    with output_config:\n",
    "        display(selected_data)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def dropdown_config_eventhandler(change):\n",
    "    common_filtering(change.new, dropdown_patho.value)\n",
    "    \n",
    "def dropdown_patho_eventhandler(change):\n",
    "    common_filtering(dropdown_config.value, change.new)\n",
    "    \n",
    "dropdown_config.observe(dropdown_config_eventhandler, names='value')\n",
    "dropdown_patho.observe(dropdown_patho_eventhandler, names='value')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0f47e48008408da8d63a84ebd4701e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Configuration', options=('configCC7-0', 'configCC7-1', 'coâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(dashboard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
